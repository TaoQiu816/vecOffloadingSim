# çŸ­æœŸéªŒè¯è®­ç»ƒ vs å®Œæ•´è®­ç»ƒå¯¹æ¯”

## å¿«é€Ÿå¯¹æ¯”è¡¨

| ç»´åº¦ | çŸ­æœŸéªŒè¯è®­ç»ƒï¼ˆå½“å‰ï¼‰ | å®Œæ•´è®­ç»ƒï¼ˆåç»­ï¼‰ |
|------|---------------------|-----------------|
| **ç›®çš„** | å¿«é€ŸéªŒè¯å‚æ•°æœ‰æ•ˆæ€§ | å……åˆ†è®­ç»ƒè·å¾—æœ€ä¼˜ç­–ç•¥ |
| **Episodes** | **300** | 1500-3000 |
| **æ—¶é•¿** | **50-75åˆ†é’Ÿ** | 4-10å°æ—¶ |
| **LRè¡°å‡é¢‘ç‡** | æ¯100 episodes (3æ¬¡) | æ¯200 episodes (7-15æ¬¡) |
| **Biasè¡°å‡é¢‘ç‡** | æ¯100 episodes (3æ¬¡) | æ¯200 episodes (7-15æ¬¡) |
| **ä¿å­˜é¢‘ç‡** | æ¯100 episodes (4ä¸ª) | æ¯200 episodes (7-15ä¸ª) |
| **è¯„ä¼°é¢‘ç‡** | æ¯25 episodes (12æ¬¡) | æ¯50 episodes (30-60æ¬¡) |
| **Task SRç›®æ ‡** | **> 10%** | > 60% |
| **Decisionç›®æ ‡** | å¼€å§‹å¹³è¡¡ | æœ€ä¼˜å¹³è¡¡ |
| **Entropyç›®æ ‡** | å¼€å§‹æ”¶æ•› | å®Œå…¨æ”¶æ•› |

---

## å½“å‰é…ç½®ï¼ˆçŸ­æœŸéªŒè¯ï¼‰

```python
# configs/train_config.py

# è®­ç»ƒè§„æ¨¡
MAX_EPISODES = 300              # çŸ­æœŸéªŒè¯
LR_DECAY_STEPS = 100            # å¿«é€Ÿè¡°å‡
BIAS_DECAY_EVERY_EP = 100       # å¿«é€Ÿè¡°å‡
SAVE_INTERVAL = 100             # é¢‘ç¹ä¿å­˜
EVAL_INTERVAL = 25              # é¢‘ç¹è¯„ä¼°

# æ ¸å¿ƒå‚æ•°ï¼ˆå·²ä¼˜åŒ–ï¼‰
ENTROPY_COEF = 0.005            # æ§åˆ¶æ¢ç´¢
MINI_BATCH_SIZE = 256           # ç¨³å®šæ€§
LOGIT_BIAS_RSU = 2.0            # å¹³è¡¡åç½®
LOGIT_BIAS_LOCAL = 1.5          # å¹³è¡¡åç½®
```

**éªŒè¯ç›®æ ‡:**
- âœ… Task Success Rateä»0%æå‡åˆ°>10%
- âœ… Decisionåˆ†å¸ƒä¸å†100% RSU
- âœ… Entropyæ”¶æ•›ï¼Œä¸å†æŒç»­å¢é•¿
- âœ… æ— è®­ç»ƒå´©æºƒ

---

## å®Œæ•´è®­ç»ƒé…ç½®ï¼ˆéªŒè¯æˆåŠŸååˆ‡æ¢ï¼‰

```python
# configs/train_config.py

# è®­ç»ƒè§„æ¨¡
MAX_EPISODES = 1500             # å®Œæ•´è®­ç»ƒï¼ˆæˆ–2000-3000ï¼‰
LR_DECAY_STEPS = 200            # ç¨³å®šè¡°å‡
BIAS_DECAY_EVERY_EP = 200       # ç¨³å®šè¡°å‡
SAVE_INTERVAL = 200             # é€‚åº¦ä¿å­˜
EVAL_INTERVAL = 50              # é€‚åº¦è¯„ä¼°

# æ ¸å¿ƒå‚æ•°ï¼ˆç»§æ‰¿éªŒè¯é…ç½®ï¼‰
ENTROPY_COEF = 0.005            # ä¿æŒ
MINI_BATCH_SIZE = 256           # ä¿æŒ
LOGIT_BIAS_RSU = 2.0            # ä¿æŒ
LOGIT_BIAS_LOCAL = 1.5          # ä¿æŒ
```

**è®­ç»ƒç›®æ ‡:**
- âœ… Task Success Rate > 60%
- âœ… Decisionåˆ†å¸ƒ: Local 30-40%, RSU 40-50%, V2V 10-20%
- âœ… Entropyç¨³å®šåœ¨0.5-1.0
- âœ… Rewardæ”¶æ•›åˆ°æ¥è¿‘æœ€ä¼˜

---

## åˆ‡æ¢æµç¨‹

### ç¬¬ä¸€æ­¥ï¼šè¿è¡ŒçŸ­æœŸéªŒè¯ï¼ˆå½“å‰ï¼‰

```bash
cd /Users/qiutao/ç ”/æ¯•è®¾/æ¯•è®¾/vecOffloadingSim
python train.py
```

**è¿è¡Œæ—¶é—´**: 50-75åˆ†é’Ÿ

### ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥éªŒè¯ç»“æœ

```bash
# æŸ¥çœ‹æœ€å50ä¸ªepisodesçš„ç»Ÿè®¡
python -c "
import pandas as pd
df = pd.read_csv('runs/run_*/episode_log.csv')
print(df.tail(50).describe())
"

# æŸ¥çœ‹å›¾è¡¨
python test_plotting.py --run-dir runs/run_*
```

**åˆ¤æ–­æ ‡å‡†:**
- âœ… Task SR > 5% â†’ ç»§ç»­
- âœ… Decisionä¸æ˜¯100%å•ä¸€ â†’ ç»§ç»­
- âœ… Entropy < 1.5 â†’ ç»§ç»­
- âœ… Rewardæœ‰å¢é•¿ â†’ ç»§ç»­

### ç¬¬ä¸‰æ­¥ï¼šåˆ‡æ¢åˆ°å®Œæ•´è®­ç»ƒ

**å¦‚æœéªŒè¯æˆåŠŸ:**

```bash
# æ–¹æ³•1: ä¿®æ”¹é…ç½®ï¼Œä»å¤´è®­ç»ƒ
vim configs/train_config.py
# ä¿®æ”¹ MAX_EPISODES = 1500
# ä¿®æ”¹ LR_DECAY_STEPS = 200
# ä¿®æ”¹ BIAS_DECAY_EVERY_EP = 200
# ä¿®æ”¹ SAVE_INTERVAL = 200
python train.py

# æ–¹æ³•2: ä»éªŒè¯checkpointç»§ç»­è®­ç»ƒï¼ˆæ¨èï¼‰
vim configs/train_config.py
# ä¿®æ”¹å‚æ•°åŒä¸Š
python train.py --load runs/run_XXXXXX/models/latest_model.pth --start-episode 300
```

---

## å‚æ•°æ¼”åŒ–å¯¹æ¯”

### çŸ­æœŸéªŒè¯ï¼ˆ300 episodesï¼‰

```
Biasæ¼”åŒ–:
Episode   0: RSU=2.0, Local=1.5
Episode 100: RSU=1.5, Local=1.2 (ç¬¬1æ¬¡è¡°å‡)
Episode 200: RSU=1.0, Local=0.9 (ç¬¬2æ¬¡è¡°å‡)
Episode 300: RSU=0.5, Local=0.5 (ç¬¬3æ¬¡è¡°å‡ï¼Œè¾¾åˆ°min)

LRæ¼”åŒ–:
Episode   0: Actor=3e-4, Critic=1e-3
Episode 100: Actor=2.76e-4, Critic=0.92e-3
Episode 200: Actor=2.54e-4, Critic=0.85e-3
Episode 300: Actor=2.34e-4, Critic=0.78e-3
```

### å®Œæ•´è®­ç»ƒï¼ˆ1500 episodesï¼‰

```
Biasæ¼”åŒ–:
Episode   0: RSU=2.0, Local=1.5
Episode 200: RSU=1.5, Local=1.2 (ç¬¬1æ¬¡è¡°å‡)
Episode 400: RSU=1.0, Local=0.9 (ç¬¬2æ¬¡è¡°å‡)
Episode 600: RSU=0.5, Local=0.6 (ç¬¬3æ¬¡è¡°å‡)
Episode 800: RSU=0.5, Local=0.5 (ç¬¬4æ¬¡è¡°å‡ï¼Œè¾¾åˆ°min)
...
Episode 1400: RSU=0.5, Local=0.5 (ä¿æŒmin)

LRæ¼”åŒ–:
Episode    0: Actor=3e-4
Episode  200: Actor=2.76e-4
Episode  400: Actor=2.54e-4
...
Episode 1400: Actor=1.68e-4
```

---

## é¢„æœŸå­¦ä¹ æ›²çº¿

### çŸ­æœŸéªŒè¯ï¼ˆ300 episodesï¼‰

```
Task Success Rate:
  0-50:   0-5%    (åˆå§‹æ¢ç´¢)
 50-100:  5-10%   (å¼€å§‹å­¦ä¹ )
100-200: 10-20%   (æŒç»­æå‡)
200-300: 15-25%   (è¶‹äºç¨³å®š)

Reward:
  0-50:  -4.5 ~ -3.5  (æ¢ç´¢æœŸ)
 50-100: -3.5 ~ -2.5  (å­¦ä¹ æœŸ)
100-200: -2.5 ~ -1.5  (æå‡æœŸ)
200-300: -1.5 ~ -1.0  (ç¨³å®šæœŸ)

Entropy:
  0-50:  1.8 ~ 1.5  (é«˜æ¢ç´¢)
 50-100: 1.5 ~ 1.2  (é™ä½)
100-200: 1.2 ~ 1.0  (æ”¶æ•›ä¸­)
200-300: 1.0 ~ 0.8  (æ¥è¿‘æ”¶æ•›)
```

### å®Œæ•´è®­ç»ƒï¼ˆ1500 episodesï¼‰

```
Task Success Rate:
    0-200:  0-20%   (åŒéªŒè¯æœŸ)
  200-500: 20-40%   (å¿«é€Ÿæå‡)
  500-1000:40-60%  (ç¨³å®šæå‡)
 1000-1500:60-75%  (æ¥è¿‘æœ€ä¼˜)

Reward:
    0-200: -4.5 ~ -1.5  (åŒéªŒè¯æœŸ)
  200-500: -1.5 ~ -0.5  (å¿«é€Ÿæå‡)
  500-1000:-0.5 ~  0.5  (ç¨³å®šæå‡)
 1000-1500: 0.5 ~  1.0  (æ¥è¿‘æœ€ä¼˜)

Entropy:
    0-200: 1.8 ~ 1.0  (åŒéªŒè¯æœŸ)
  200-500: 1.0 ~ 0.7  (æŒç»­æ”¶æ•›)
  500-1500:0.7 ~ 0.5  (ç¨³å®šæ”¶æ•›)
```

---

## è°ƒè¯•ç­–ç•¥

### çŸ­æœŸéªŒè¯é˜¶æ®µ

**å‡ºç°é—®é¢˜ â†’ å¿«é€Ÿè°ƒæ•´ â†’ é‡æ–°éªŒè¯ï¼ˆæˆæœ¬ä½ï¼‰**

å¸¸è§è°ƒæ•´:
- Task SR=0% â†’ å¢åŠ BW_V2Iæˆ–é™ä½æ•°æ®é‡
- Decision 100% RSU â†’ é™ä½LOGIT_BIAS_RSU
- EntropyæŒç»­å¢é•¿ â†’ é™ä½ENTROPY_COEF
- è®­ç»ƒå´©æºƒ â†’ é™ä½å­¦ä¹ ç‡

### å®Œæ•´è®­ç»ƒé˜¶æ®µ

**è°¨æ…è°ƒæ•´ï¼Œä¼˜å…ˆåˆ†æå†ä¿®æ”¹ï¼ˆæˆæœ¬é«˜ï¼‰**

è°ƒæ•´åŸåˆ™:
- å‰500 episodeså‡ºé—®é¢˜ â†’ å¯è€ƒè™‘é‡å¯
- 500-1000 episodes â†’ å¾®è°ƒå‚æ•°ç»§ç»­
- 1000+ episodes â†’ ä¸€èˆ¬ä¸è°ƒæ•´

---

## ç¡¬ä»¶éœ€æ±‚å¯¹æ¯”

| é¡¹ç›® | çŸ­æœŸéªŒè¯ | å®Œæ•´è®­ç»ƒ |
|------|---------|----------|
| **GPUæ˜¾å­˜** | > 4GB | > 6GB (æ¨è8GB+) |
| **å†…å­˜** | > 8GB | > 16GB |
| **å­˜å‚¨ç©ºé—´** | ~500MB | ~2-3GB |
| **GPUç±»å‹** | GTX 1660+ | RTX 3060+ |
| **CPU** | 4æ ¸+ | 8æ ¸+ (æ¨è) |

---

## å¸¸è§é—®é¢˜

### Q1: éªŒè¯è®­ç»ƒ300 episodeså¤Ÿå—ï¼Ÿ

**A**: å¤Ÿã€‚ç›®æ ‡æ˜¯éªŒè¯é…ç½®ï¼Œä¸æ˜¯è®­ç»ƒåˆ°æœ€ä¼˜ã€‚å¦‚æœ300 episodesèƒ½çœ‹åˆ°ï¼š
- Task SRä»0%æå‡åˆ°>5%
- Decisionå¼€å§‹å¹³è¡¡
- Entropyå¼€å§‹æ”¶æ•›

å°±è¯´æ˜é…ç½®æœ‰æ•ˆï¼Œå¯ä»¥ç»§ç»­å®Œæ•´è®­ç»ƒã€‚

### Q2: èƒ½å¦ç›´æ¥è·³è¿‡éªŒè¯ï¼Œå¼€å§‹å®Œæ•´è®­ç»ƒï¼Ÿ

**A**: ä¸æ¨èã€‚å®Œæ•´è®­ç»ƒè€—æ—¶é•¿ï¼ˆ4-10å°æ—¶ï¼‰ï¼Œå¦‚æœé…ç½®æœ‰é—®é¢˜ï¼Œæµªè´¹æ—¶é—´æˆæœ¬é«˜ã€‚çŸ­æœŸéªŒè¯åªéœ€1å°æ—¶ï¼Œå¯ä»¥å¿«é€Ÿå‘ç°é—®é¢˜ã€‚

### Q3: éªŒè¯å¤±è´¥åéœ€è¦é‡æ–°å¼€å§‹å—ï¼Ÿ

**A**: ä¸€èˆ¬éœ€è¦ã€‚ä½†å¯ä»¥åˆ†ææœ€åçš„checkpointï¼Œåˆ¤æ–­æ˜¯å¦åªéœ€å¾®è°ƒã€‚å¦‚æœæ˜¯LOGIT_BIASé—®é¢˜ï¼Œå¯ä»¥ä¿®æ”¹é…ç½®åcontinueè®­ç»ƒã€‚

### Q4: èƒ½å¦ä»éªŒè¯checkpointç»§ç»­åˆ°å®Œæ•´è®­ç»ƒï¼Ÿ

**A**: å¯ä»¥ï¼ˆæ¨èï¼‰ã€‚ä½¿ç”¨ `--load` å‚æ•°ï¼š

```bash
python train.py --load runs/run_XXXXXX/models/latest_model.pth --start-episode 300
```

è¿™æ ·å¯ä»¥èŠ‚çœ300 episodesçš„æ—¶é—´ã€‚

---

## å½“å‰çŠ¶æ€

âœ… **é…ç½®å·²ä¼˜åŒ–**: ç¯å¢ƒå‚æ•°å’Œè®­ç»ƒå‚æ•°å·²è°ƒæ•´  
âœ… **çŸ­æœŸéªŒè¯é…ç½®**: MAX_EPISODES=300ï¼Œé€‚åˆå¿«é€ŸéªŒè¯  
â³ **ç­‰å¾…è¿è¡Œ**: è¿è¡Œ `python train.py` å¼€å§‹éªŒè¯è®­ç»ƒ  
ğŸ“Š **ç»“æœåˆ†æ**: ä½¿ç”¨VALIDATION_TRAINING_GUIDE.mdåˆ¤æ–­ç»“æœ  

---

**è¿è¡Œå‘½ä»¤:**
```bash
python train.py
```

**é¢„è®¡æ—¶é—´**: 50-75åˆ†é’Ÿ  
**éªŒè¯ç›®æ ‡**: Task SR > 10%, Decisionå¹³è¡¡, Entropyæ”¶æ•›

